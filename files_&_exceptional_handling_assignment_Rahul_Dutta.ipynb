{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzTrJwXEa8elAzf9PM84G4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Q1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YEiK_iuz_OVB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans1.** Multithreading and multiprocessing are both used to improve the performance of programs by allowing multiple operations to run simultaneously. However, they are suited for different scenarios based on the nature of the task and the system's architecture. Here’s a breakdown of when each approach is preferable:\n",
        "\n",
        "### When to Use Multithreading\n",
        "Multithreading is ideal when:\n",
        "1. **Tasks are I/O-Bound:** If the program is frequently waiting for I/O operations (like reading from files, databases, or the network), multithreading works well. Multiple threads can handle I/O operations simultaneously, making the overall process faster without adding much CPU load.\n",
        "   \n",
        "2. **Shared Memory and Low Overhead Needed:** Threads in the same process share memory, which makes data sharing and communication between them faster. If you need multiple operations to work on the same data or if you want to minimize the memory usage, multithreading is a better option.\n",
        "\n",
        "3. **Programs Have Lightweight Tasks:** Threads are generally lighter than processes, so if tasks don’t require much computation, you can avoid the extra memory and overhead associated with creating multiple processes by using threads instead.\n",
        "\n",
        "**Example Scenario:** Web servers often use multithreading because they handle numerous requests (mostly I/O-bound) simultaneously. Each request is usually lightweight, involving quick reads/writes from/to databases or sending data over the network.\n",
        "\n",
        "### When to Use Multiprocessing\n",
        "Multiprocessing is more suitable when:\n",
        "1. **Tasks are CPU-Bound:** If the tasks require heavy computation, like data analysis or mathematical processing, multiprocessing is better. Since each process gets its own memory space and can use a separate CPU core, multiprocessing can significantly speed up CPU-intensive tasks.\n",
        "\n",
        "2. **Avoiding Global Interpreter Lock (GIL):** Python’s GIL restricts CPU-bound threads from running in true parallel. Multiprocessing, on the other hand, spawns separate processes with their own GIL, allowing them to run in parallel and fully utilize multi-core systems.\n",
        "\n",
        "3. **Isolation is Needed:** Each process runs in its own memory space, so if tasks need to be isolated for security or error tolerance (where one task’s failure shouldn’t affect others), multiprocessing is safer and more reliable.\n",
        "\n",
        "**Example Scenario:** Data analysis or machine learning tasks that perform heavy calculations often use multiprocessing to leverage all CPU cores and speed up processing time."
      ],
      "metadata": {
        "id": "0wiymoex_btq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2. Describe what a process pool is and how it helps in managing multiple processes efficiently**"
      ],
      "metadata": {
        "id": "Z3AfX6SR_jtb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans2.** A **process pool** is a mechanism used in multiprocessing to manage and control a group of worker processes that can execute tasks in parallel. Instead of creating and destroying a new process for each task, a process pool allows you to maintain a fixed number of processes that can be reused to handle multiple tasks. This approach reduces the overhead associated with creating and destroying processes repeatedly and helps in efficiently managing resources.\n",
        "\n",
        "### How a Process Pool Works\n",
        "1. **Initialization:** When you create a process pool, a fixed number of worker processes are initialized. This number is typically based on the number of CPU cores, though it can be adjusted as needed.\n",
        "   \n",
        "2. **Task Allocation:** Tasks are assigned to the worker processes in the pool. The pool automatically distributes tasks among the available processes, ensuring each one is efficiently utilized.\n",
        "\n",
        "3. **Reusability:** Once a worker process completes a task, it becomes available to handle the next one. This reusability saves time and reduces the computational cost of starting and stopping processes.\n",
        "\n",
        "4. **Automatic Management:** The process pool manages tasks and assigns them to idle processes. If all processes are busy, new tasks are queued until a process becomes available.\n",
        "\n",
        "### Benefits of Using a Process Pool\n",
        "- **Reduced Overhead:** Process pools reduce the overhead associated with creating and destroying processes for each task, as the same set of processes can handle multiple tasks over time.\n",
        "  \n",
        "- **Efficient Resource Usage:** By limiting the number of processes, process pools prevent excessive memory usage and CPU strain that can happen if too many processes are spawned.\n",
        "\n",
        "- **Simplified Parallelism:** With a process pool, managing parallel tasks becomes simpler. You can pass tasks to the pool and let it handle the scheduling and execution, allowing you to focus on your application’s logic.\n",
        "\n",
        "### Example Scenario:\n",
        "Suppose you have a program that needs to process thousands of images. Instead of creating a new process for each image, which would be highly inefficient, you could use a process pool with a fixed number of processes. Each process can take an image, process it, and then move on to the next image, ensuring a balance between performance and resource usage.\n",
        "\n",
        "In Python, the `multiprocessing.Pool` class provides an easy-to-use process pool, where you can specify the number of worker processes and use functions like `map()`, `apply()`, and `starmap()` to distribute tasks across the pool efficiently."
      ],
      "metadata": {
        "id": "mo-hS4NB_qKD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3. Explain what multiprocessing is and why it is used in Python programs.**"
      ],
      "metadata": {
        "id": "IqhaK3OLBKCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans3.** **Multiprocessing** is a programming technique that allows multiple processes (independent units of execution) to run simultaneously, typically across multiple CPU cores. In Python, the `multiprocessing` module enables the creation and management of these processes. Each process runs independently and has its own memory space, which makes multiprocessing useful for handling tasks that can be run in parallel, improving the program's performance, especially for CPU-bound tasks.\n",
        "\n",
        "### Why Multiprocessing is Used in Python\n",
        "1. **Overcoming the Global Interpreter Lock (GIL):** In Python, the **Global Interpreter Lock (GIL)** restricts threads from executing Python bytecode in true parallel, which limits the benefits of threading for CPU-bound tasks. Multiprocessing, however, uses separate memory spaces and interpreters for each process, bypassing the GIL and allowing true parallelism.\n",
        "\n",
        "2. **Enhanced Performance for CPU-Bound Tasks:** Tasks that require heavy computation, like data processing, scientific calculations, or machine learning model training, can slow down a program if executed sequentially. Multiprocessing allows these tasks to run across multiple cores, significantly speeding up execution.\n",
        "\n",
        "3. **Better Resource Utilization on Multi-Core Systems:** Modern systems typically have multiple cores, but a single-threaded Python program can only use one core at a time. By leveraging multiprocessing, Python programs can take full advantage of multi-core architectures, improving overall system efficiency.\n",
        "\n",
        "4. **Process Isolation for Stability and Security:** Each process in multiprocessing has its own memory space, so they run independently of each other. If one process crashes or encounters an error, it won’t affect the other processes, making multiprocessing a good choice for tasks where stability and isolation are important.\n",
        "\n",
        "### Example of When to Use Multiprocessing\n",
        "If a program needs to analyze large datasets or perform complex mathematical operations, multiprocessing allows these operations to be split into smaller tasks that run on different cores, completing the work faster than a single-threaded approach.\n",
        "\n",
        "Python’s `multiprocessing` module makes it easy to create processes and manage their execution, using classes and functions like `Process`, `Pool`, and `Queue` to facilitate parallelism, inter-process communication, and task management."
      ],
      "metadata": {
        "id": "ayDoQZniBMOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock.**"
      ],
      "metadata": {
        "id": "AkOVo1adBSLh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans4.** Here’s a Python program that uses multithreading to have one thread add numbers to a list and another thread remove numbers from the list. To avoid race conditions (where threads might interfere with each other’s actions), we’ll use threading.Lock. This lock ensures that only one thread can access the shared list at a time, preventing any conflicts."
      ],
      "metadata": {
        "id": "HTfMivb5Bysm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "# Shared list\n",
        "numbers = []\n",
        "\n",
        "# Lock object to prevent race conditions\n",
        "lock = threading.Lock()\n",
        "\n",
        "# Function for the thread to add numbers to the list\n",
        "def add_numbers():\n",
        "    for i in range(1, 6):  # Add numbers from 1 to 5\n",
        "        lock.acquire()  # Acquire the lock\n",
        "        try:\n",
        "            numbers.append(i)\n",
        "            print(f\"Added {i} to the list. List now: {numbers}\")\n",
        "        finally:\n",
        "            lock.release()  # Release the lock\n",
        "        time.sleep(0.5)  # Pause for a bit to simulate processing time\n",
        "\n",
        "# Function for the thread to remove numbers from the list\n",
        "def remove_numbers():\n",
        "    for _ in range(5):  # Remove 5 numbers\n",
        "        time.sleep(1)  # Pause to allow adding first\n",
        "        lock.acquire()  # Acquire the lock\n",
        "        try:\n",
        "            if numbers:\n",
        "                removed = numbers.pop(0)\n",
        "                print(f\"Removed {removed} from the list. List now: {numbers}\")\n",
        "            else:\n",
        "                print(\"List is empty, nothing to remove.\")\n",
        "        finally:\n",
        "            lock.release()  # Release the lock\n",
        "\n",
        "# Create threads\n",
        "thread1 = threading.Thread(target=add_numbers)\n",
        "thread2 = threading.Thread(target=remove_numbers)\n",
        "\n",
        "# Start threads\n",
        "thread1.start()\n",
        "thread2.start()\n",
        "\n",
        "# Wait for both threads to complete\n",
        "thread1.join()\n",
        "thread2.join()\n",
        "\n",
        "print(\"Final list:\", numbers)\n"
      ],
      "metadata": {
        "id": "q9DtjJePB2UN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation of the Program**\n",
        "\n",
        "Shared List and Lock: We create a shared list numbers and a lock to control access to it.\n",
        "Add Function: The add_numbers function adds numbers (1 to 5) to the list, locking access each time a number is added to prevent interference from the removal thread.\n",
        "Remove Function: The remove_numbers function removes numbers from the beginning of the list. It also locks access to prevent conflicts.\n",
        "Thread Execution: Two threads (thread1 and thread2) are created, one to run add_numbers and the other to run remove_numbers.\n",
        "Lock Usage: The lock ensures that only one thread can modify the list at any given time, avoiding race conditions.\n",
        "\n",
        "\n",
        "**Sample Output**"
      ],
      "metadata": {
        "id": "90A-tqbuB70u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpiETDpS-kJO"
      },
      "outputs": [],
      "source": [
        "Added 1 to the list. List now: [1]\n",
        "Added 2 to the list. List now: [1, 2]\n",
        "Removed 1 from the list. List now: [2]\n",
        "Added 3 to the list. List now: [2, 3]\n",
        "Removed 2 from the list. List now: [3]\n",
        "...\n",
        "Final list: []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using threading.Lock ensures safe access to the shared list, preventing race conditions that might otherwise cause unpredictable behavior."
      ],
      "metadata": {
        "id": "91ormiyTCEQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5. Describe the methods and tools available in Python for safely sharing data between threads and processes.**"
      ],
      "metadata": {
        "id": "NmFz75UiCL3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans5.** In Python, sharing data safely between threads and processes requires careful handling to avoid conflicts or race conditions. The `threading` and `multiprocessing` modules offer various methods and tools to manage data sharing safely and efficiently. Here’s an overview of some of these tools:\n",
        "\n",
        "### 1. Tools for Sharing Data Between Threads\n",
        "For **threads**, Python provides mechanisms within the same memory space, as threads share memory by default in the same process. Here are a few key tools:\n",
        "\n",
        "- **threading.Lock**: A lock is the simplest synchronization tool. Only one thread can acquire the lock at a time, ensuring exclusive access to a shared resource. Other threads attempting to acquire the lock must wait until it’s released.\n",
        "  \n",
        "- **threading.RLock** (Reentrant Lock): This is a lock that a single thread can acquire multiple times without causing a deadlock. It’s helpful if a thread needs to acquire the lock in a nested fashion (e.g., in recursive functions).\n",
        "\n",
        "- **threading.Semaphore**: A semaphore controls access to a resource by allowing a limited number of threads to acquire it simultaneously. This is useful when you have a shared resource that can be accessed by multiple threads but only up to a certain limit.\n",
        "\n",
        "- **threading.Event**: An event is a flag that threads can check or set. It allows threads to communicate with each other, typically used to signal that a particular condition has been met.\n",
        "\n",
        "- **threading.Queue**: A thread-safe queue is one of the safest ways to share data between threads. Python’s `Queue` class handles locking internally, allowing threads to add or remove items without explicit locks. Queues support FIFO (First-In-First-Out), LIFO (Last-In-First-Out), and priority-based ordering.\n",
        "\n",
        "### 2. Tools for Sharing Data Between Processes\n",
        "For **processes**, each process has its own memory space, so sharing data is more complex. The `multiprocessing` module provides several tools to enable safe data sharing:\n",
        "\n",
        "- **multiprocessing.Queue**: Like `threading.Queue`, `multiprocessing.Queue` allows for safe data exchange between processes. It uses inter-process communication (IPC) mechanisms to allow different processes to put and get data in a FIFO manner.\n",
        "\n",
        "- **multiprocessing.Pipe**: A pipe provides a two-way communication channel between two processes. You can use it to send and receive data between processes. Each end of the pipe is independent, so each process can safely read from or write to it.\n",
        "\n",
        "- **multiprocessing.Value** and **multiprocessing.Array**: These tools allow processes to share simple data (like integers or arrays) in shared memory. `Value` is used for single values, while `Array` is used for a fixed-size array. Both support synchronization using locks, which ensures only one process can modify the data at a time.\n",
        "\n",
        "- **multiprocessing.Manager**: The `Manager` class provides a higher-level interface for creating shared data structures like dictionaries, lists, and namespaces that can be safely shared between processes. It handles synchronization internally, so you don’t need to worry about locking.\n",
        "\n",
        "- **Shared Memory (Python 3.8+)**: Python’s `multiprocessing.shared_memory` module allows you to share a block of memory between processes without the overhead of serializing and deserializing data. You can create or attach to a shared memory block, which can be accessed directly by different processes, making it efficient for sharing large data.\n",
        "\n",
        "### 3. Concurrent Data Structures\n",
        "Python’s `concurrent.futures` module provides `ThreadPoolExecutor` and `ProcessPoolExecutor`, which offer higher-level abstractions for managing threads and processes. They support shared data through futures, which represent the results of asynchronous computations, and handle data synchronization internally.\n",
        "\n",
        "- **Futures and Executors**: The `concurrent.futures.Future` object allows you to submit tasks to be run by threads or processes and retrieve their results once completed. `ThreadPoolExecutor` and `ProcessPoolExecutor` provide a way to manage a pool of threads or processes for task execution.\n",
        "\n",
        "### Summary Table\n",
        "\n",
        "| Tool                         | Best Used For                          | Suitable For        |\n",
        "|------------------------------|----------------------------------------|----------------------|\n",
        "| **threading.Lock**           | Exclusive access to a shared resource | Threads             |\n",
        "| **threading.RLock**          | Re-entrant locking                    | Threads             |\n",
        "| **threading.Semaphore**      | Limited access to a shared resource   | Threads             |\n",
        "| **threading.Event**          | Communication between threads         | Threads             |\n",
        "| **threading.Queue**          | Thread-safe FIFO/LIFO queue           | Threads             |\n",
        "| **multiprocessing.Queue**    | Process-safe queue                    | Processes           |\n",
        "| **multiprocessing.Pipe**     | Two-way communication between processes | Processes           |\n",
        "| **multiprocessing.Value/Array** | Simple shared memory structures   | Processes           |\n",
        "| **multiprocessing.Manager**  | Shared data structures like lists/dicts | Processes           |\n",
        "| **multiprocessing.shared_memory** | Large shared data                 | Processes           |\n",
        "| **concurrent.futures**       | Task management for threads/processes | Both                |\n",
        "\n",
        "These tools allow for safe, synchronized access to shared data, ensuring data integrity and preventing race conditions in Python programs."
      ],
      "metadata": {
        "id": "Akwvfe1mCQv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so.**"
      ],
      "metadata": {
        "id": "jbmITSwpCmk8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans6.** Handling exceptions in concurrent programs is crucial because, in multi-threaded or multi-process environments, an unhandled exception in one thread or process can lead to unpredictable program behavior, data corruption, or incomplete tasks. Moreover, it can sometimes be harder to detect and manage exceptions in concurrent programs than in single-threaded programs. Here’s a breakdown of why exception handling is essential in concurrency and the techniques available to manage it effectively.\n",
        "\n",
        "### Why Exception Handling is Important in Concurrent Programs\n",
        "1. **Avoiding Silent Failures**: In concurrent programs, an exception in one thread or process might go unnoticed if not handled, leading to silent failures. The main program may continue running without knowing that a task has failed, potentially causing incorrect results.\n",
        "\n",
        "2. **Preventing Data Corruption**: Many concurrent programs share resources or data across threads or processes. If one thread or process encounters an error while accessing shared data and it isn’t handled, this can corrupt the data, affecting other threads or processes that rely on it.\n",
        "\n",
        "3. **Ensuring Task Completion**: Without proper exception handling, some tasks may only be partially completed, especially if a thread or process exits unexpectedly. This can leave the program in an inconsistent state and affect subsequent tasks.\n",
        "\n",
        "4. **Debugging and Maintenance**: Unhandled exceptions make it harder to debug concurrent programs, as tracing errors through multiple threads or processes can be complex. Proper exception handling helps log errors and provides useful information for debugging.\n",
        "\n",
        "### Techniques for Handling Exceptions in Concurrent Programs\n",
        "\n",
        "#### 1. **Try-Except Blocks in Each Thread or Process**\n",
        "   - The most straightforward approach is to use `try-except` blocks within the target function of each thread or process. This way, if an exception occurs, it can be handled or logged locally within that function, without affecting the entire program.\n",
        "   - Example:"
      ],
      "metadata": {
        "id": "dMBjf3R9Dv0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "     import threading\n",
        "\n",
        "     def task():\n",
        "         try:\n",
        "             # Code that might raise an exception\n",
        "             result = 1 / 0  # Example error\n",
        "         except Exception as e:\n",
        "             print(f\"Exception in thread: {e}\")\n",
        "\n",
        "     thread = threading.Thread(target=task)\n",
        "     thread.start()\n",
        "     thread.join()"
      ],
      "metadata": {
        "id": "bxTuvIXtD0fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. **Using Thread or Process Pool Executors (with concurrent.futures)**\n",
        "   - Python’s `concurrent.futures` module provides `ThreadPoolExecutor` and `ProcessPoolExecutor`, which allow you to manage threads or processes and handle exceptions using `Future` objects.\n",
        "   - If an exception occurs, it’s captured by the `Future` object associated with that task, and you can retrieve or handle it when calling `future.result()`.\n",
        "   - Example:"
      ],
      "metadata": {
        "id": "BNAceUJED3BG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "     from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "     def task():\n",
        "         return 1 / 0  # This will raise an exception\n",
        "\n",
        "     with ThreadPoolExecutor() as executor:\n",
        "         future = executor.submit(task)\n",
        "         try:\n",
        "             result = future.result()  # This will raise the exception\n",
        "         except Exception as e:\n",
        "             print(f\"Exception in thread pool: {e}\")"
      ],
      "metadata": {
        "id": "vvo7sm66D4xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. **Exception Propagation in Multiprocessing**\n",
        "   - In the `multiprocessing` module, exceptions raised in a child process don’t automatically propagate to the parent. However, you can capture exceptions in the child process and use `multiprocessing.Queue` to pass them back to the parent process for handling.\n",
        "   - Example:"
      ],
      "metadata": {
        "id": "JlaUKvVFD93_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "     import multiprocessing\n",
        "\n",
        "     def task(queue):\n",
        "         try:\n",
        "             result = 1 / 0  # This will raise an exception\n",
        "         except Exception as e:\n",
        "             queue.put(e)  # Send exception to the parent process\n",
        "\n",
        "     queue = multiprocessing.Queue()\n",
        "     process = multiprocessing.Process(target=task, args=(queue,))\n",
        "     process.start()\n",
        "     process.join()\n",
        "\n",
        "     if not queue.empty():\n",
        "         error = queue.get()\n",
        "         print(f\"Exception in process: {error}\")"
      ],
      "metadata": {
        "id": "-K-zTsi6EARf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. **Using Custom Logging for Exception Tracking**\n",
        "   - Logging is essential in concurrent programs to track when and where exceptions occur. Use Python’s `logging` module to log exceptions in each thread or process, which can help you monitor issues without stopping the entire program.\n",
        "   - Example:"
      ],
      "metadata": {
        "id": "J-NhFyetEDVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "     import logging\n",
        "     import threading\n",
        "\n",
        "     logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "     def task():\n",
        "         try:\n",
        "             result = 1 / 0\n",
        "         except Exception as e:\n",
        "             logging.error(f\"Exception in thread: {e}\")\n",
        "\n",
        "     thread = threading.Thread(target=task)\n",
        "     thread.start()\n",
        "     thread.join()"
      ],
      "metadata": {
        "id": "SqBmN6nOEFzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. **Timeouts for Managing Long-Running Tasks**\n",
        "   - For tasks that may hang or take too long, setting timeouts can help prevent the main program from waiting indefinitely. In `concurrent.futures`, you can specify a timeout for `future.result()` to handle tasks that exceed expected durations.\n",
        "   - Example:"
      ],
      "metadata": {
        "id": "pZC65SiwEJIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "     from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
        "\n",
        "     def task():\n",
        "         import time\n",
        "         time.sleep(5)\n",
        "\n",
        "     with ThreadPoolExecutor() as executor:\n",
        "         future = executor.submit(task)\n",
        "         try:\n",
        "             result = future.result(timeout=2)  # Timeout set to 2 seconds\n",
        "         except TimeoutError:\n",
        "             print(\"Task timed out\")"
      ],
      "metadata": {
        "id": "pWk9tpOxEMzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. **Graceful Shutdown with Thread and Process Management**\n",
        "   - For critical sections of code, it’s often wise to handle exceptions by implementing a graceful shutdown. Using flags or events, you can signal other threads or processes to stop if an exception occurs, ensuring an orderly shutdown and freeing of resources."
      ],
      "metadata": {
        "id": "wiOTiYBCERCB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "### Summary Table\n",
        "\n",
        "| Technique                                | Description                                                                          |\n",
        "|------------------------------------------|--------------------------------------------------------------------------------------|\n",
        "| **Try-Except in Threads/Processes**      | Use `try-except` blocks locally in each thread or process                            |\n",
        "| **Future Exception Handling**            | Use `concurrent.futures` with `ThreadPoolExecutor` or `ProcessPoolExecutor`          |\n",
        "| **Exception Propagation in Processes**   | Capture exceptions in child processes and send back to the parent                    |\n",
        "| **Logging for Exception Tracking**       | Use `logging` to track exceptions for monitoring and debugging                       |\n",
        "| **Timeouts for Long Tasks**              | Set timeouts for tasks to prevent indefinite waits                                   |\n",
        "| **Graceful Shutdown**                    | Use flags or events to signal threads/processes to stop on exception                 |\n",
        "\n"
      ],
      "metadata": {
        "id": "2vWMd9mDCpr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling exceptions properly in concurrent programs ensures stability, consistency, and reliable performance, especially for large and complex applications."
      ],
      "metadata": {
        "id": "AIVxB1KlEdND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads.**"
      ],
      "metadata": {
        "id": "DTRJjIxTEi6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans7.** Here’s a Python program that uses a **thread pool** to calculate the factorial of numbers from 1 to 10 concurrently. We’ll use `concurrent.futures.ThreadPoolExecutor` to manage the threads, and each thread will calculate the factorial of a single number."
      ],
      "metadata": {
        "id": "EzoPhHOMFZor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import math\n",
        "\n",
        "# Function to calculate the factorial of a given number\n",
        "def calculate_factorial(n):\n",
        "    result = math.factorial(n)\n",
        "    print(f\"Factorial of {n} is {result}\")\n",
        "    return result\n",
        "\n",
        "# List of numbers to calculate factorial for\n",
        "numbers = range(1, 11)\n",
        "\n",
        "# Use ThreadPoolExecutor to manage a pool of threads\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    # Submit tasks to the thread pool for each number\n",
        "    results = executor.map(calculate_factorial, numbers)\n",
        "\n",
        "# Convert results to a list to store them\n",
        "factorial_results = list(results)\n",
        "print(\"All factorials calculated:\", factorial_results)"
      ],
      "metadata": {
        "id": "ZPjDY3FLFaRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation of the Program\n",
        "\n",
        "1. **Factorial Calculation Function:** The `calculate_factorial` function takes a single number as input, calculates its factorial using `math.factorial`, and prints the result.\n",
        "  \n",
        "2. **Using `ThreadPoolExecutor`:** The `ThreadPoolExecutor` is used to manage a pool of threads. We don’t specify the number of threads, so it defaults to the number of available CPU cores.\n",
        "\n",
        "3. **Mapping Tasks to Threads:** We use `executor.map()` to apply the `calculate_factorial` function to each number in the `numbers` range concurrently. `map()` returns an iterator of results, so all calculations are completed in parallel.\n",
        "\n",
        "4. **Result Storage:** The results from each factorial calculation are stored in a list `factorial_results`, which we print at the end.\n",
        "\n",
        "### Sample Output"
      ],
      "metadata": {
        "id": "Sk0w-1OuFfCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Factorial of 1 is 1\n",
        "Factorial of 2 is 2\n",
        "Factorial of 3 is 6\n",
        "Factorial of 4 is 24\n",
        "Factorial of 5 is 120\n",
        "Factorial of 6 is 720\n",
        "Factorial of 7 is 5040\n",
        "Factorial of 8 is 40320\n",
        "Factorial of 9 is 362880\n",
        "Factorial of 10 is 3628800\n",
        "All factorials calculated: [1, 2, 6, 24, 120, 720, 5040, 40320, 362880, 3628800]"
      ],
      "metadata": {
        "id": "4NbF8aRDFioU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Using `ThreadPoolExecutor` allows each factorial calculation to run in its own thread, enabling concurrent execution. This approach is efficient for CPU-bound or independent tasks like factorial calculations."
      ],
      "metadata": {
        "id": "dd80aAuVEl4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes).**"
      ],
      "metadata": {
        "id": "6jijJ-H9Fm8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans8.** Here’s a Python program that uses `multiprocessing.Pool` to compute the square of numbers from 1 to 10 in parallel. The program also measures the time taken to perform this computation using pools of different sizes (2, 4, and 8 processes)."
      ],
      "metadata": {
        "id": "N7jgsI3sGChI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "import time\n",
        "\n",
        "# Function to compute the square of a number\n",
        "def compute_square(n):\n",
        "    return n * n\n",
        "\n",
        "# List of numbers to compute squares for\n",
        "numbers = range(1, 11)\n",
        "\n",
        "# Function to measure time taken by a pool of a given size\n",
        "def measure_time(pool_size):\n",
        "    start_time = time.time()\n",
        "\n",
        "    with Pool(pool_size) as pool:\n",
        "        results = pool.map(compute_square, numbers)\n",
        "\n",
        "    end_time = time.time()\n",
        "    time_taken = end_time - start_time\n",
        "    print(f\"Pool size {pool_size}: Results = {results}, Time taken = {time_taken:.4f} seconds\")\n",
        "\n",
        "# Test with different pool sizes\n",
        "for size in [2, 4, 8]:\n",
        "    measure_time(size)"
      ],
      "metadata": {
        "id": "dc0zEZocGC4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation of the Program\n",
        "\n",
        "1. **Square Calculation Function:** The `compute_square` function takes a number as input and returns its square.\n",
        "\n",
        "2. **Timing Function:** The `measure_time` function accepts a `pool_size` argument to specify the number of processes in the pool. It records the start time, creates a `Pool` of the specified size, and maps the `compute_square` function to each number in `numbers` using `pool.map()`. After the computation, it records the end time and calculates the time taken.\n",
        "\n",
        "3. **Testing with Different Pool Sizes:** We run `measure_time` with pool sizes of 2, 4, and 8 to observe the differences in time taken.\n",
        "\n",
        "### Expected Output\n",
        "\n",
        "The output will show the results of the square computations along with the time taken for each pool size.\n"
      ],
      "metadata": {
        "id": "UxgnkDzgGHQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Pool size 2: Results = [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken = X.XXXX seconds\n",
        "Pool size 4: Results = [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken = X.XXXX seconds\n",
        "Pool size 8: Results = [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken = X.XXXX seconds"
      ],
      "metadata": {
        "id": "DTvk6ypBGKeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Explanation of Results\n",
        "1. The program will show the results of computing the square of each number from 1 to 10.\n",
        "2. The time taken for each pool size will vary depending on the system’s resources and the overhead of creating multiple processes. Generally, using more processes can speed up the computation but might reach diminishing returns beyond a certain point, especially for small tasks."
      ],
      "metadata": {
        "id": "RQtzX2lIFro9"
      }
    }
  ]
}